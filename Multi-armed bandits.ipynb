{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4b7ca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True mean rewards [1.77 2.46 1.84 1.14 1.85 0.15 0.38 0.33 0.62 0.7  2.14]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'where'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JASKEE~1\\AppData\\Local\\Temp/ipykernel_18940/2434057680.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mestimated_means\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestmean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimated_means\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m \u001b[0mbandit_solving_algo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_bandits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Estimated mean rewards\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mestimated_means\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m '''\n",
      "\u001b[1;32mC:\\Users\\JASKEE~1\\AppData\\Local\\Temp/ipykernel_18940/2434057680.py\u001b[0m in \u001b[0;36mbandit_solving_algo\u001b[1;34m(num_bandits)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mestmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0me1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexploration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0me2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexploitation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mchoose_bandits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JASKEE~1\\AppData\\Local\\Temp/ipykernel_18940/2434057680.py\u001b[0m in \u001b[0;36mexploitation\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexploitation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mestmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[0me1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexploration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0me2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexploitation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'where'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "std=1\n",
    "mean=1\n",
    "'''\n",
    "This class simply generates a bandit problem with number of bandit arms\n",
    "being `num_bandits`, which itself is chosen randomly. The numbers being sampled\n",
    "from the gaussian are the rewards associated with those arms.\n",
    "For simplicity, I have restricted ourselved to nonnegative rewards and decimals upto 2 digits\n",
    "to avoid any floating point calculation errors.\n",
    "'''\n",
    "class Bandit_arms:\n",
    "\n",
    "    def __init__(self, num_bandits):\n",
    "        self.bandits=np.round(np.absolute(np.random.normal(loc=mean, scale=std, size=num_bandits)), decimals=2)\n",
    "\n",
    "    def return_array(self):\n",
    "        return self.bandits\n",
    "\n",
    "\n",
    "'''\n",
    "Minimum: 5 bandit arms and maximum: 20 bandit arms.\n",
    "'''\n",
    "\n",
    "num_bandits=np.random.randint(low=5, high=20,size=1)[0]\n",
    "bandit_problem=Bandit_arms(num_bandits).return_array()\n",
    "print(\"True mean rewards\",bandit_problem)\n",
    "\n",
    "'''\n",
    "This is technically cheating, you should not be aware of the true underlying \n",
    "reward through any means. It doesn't matter as beginners but keep it in mind\n",
    "that this data is unavailable to you (no need for learning if we knew already!).\n",
    "'''\n",
    "\n",
    "'''\n",
    "Now for each arm, when we pull it, we get modulus of number sampled\n",
    "from a gaussian with mean defined in `bandit_problem` array and standard\n",
    "deviation=std.\n",
    "Keep in mind that first bandit arm would have index 0.\n",
    "'''\n",
    "\n",
    "def bandit_simulator(arm_index):\n",
    "    reward=np.round(np.absolute(np.random.normal(loc=bandit_problem[arm_index], scale=std, size=1)), decimals=2)[0]\n",
    "    return reward\n",
    "\n",
    "\n",
    "'''\n",
    "So, now we have an environment that generates a bandit problem\n",
    "with a random number of arms and random mean rewards. We have a function to \n",
    "sample reward on \"pulling\" each of these arms. Now, try out algorithms that \n",
    "can come close to true mean rewards.\n",
    "Any rule based method won't work, since means change everytime you run the python file.\n",
    "So, your algorithm must truly be able to learn as good as it can in a single run of this file.\n",
    "As you must have understood by now, learning is an iterative procedure. Typically, to represent limited\n",
    "computational and time resources, upper limits on allowed learning iterations are imposed. So, I am setting \n",
    "a variable that defines number of allowed iterations. Of course, while building, you can play around with it.\n",
    "'''\n",
    "\n",
    "num_allowed_iterations=2000\n",
    "\n",
    "'''\n",
    "Except for the values of mean, std, num_iterations, I don't think you should\n",
    "have the need to change any of the code written to this point.\n",
    "'''\n",
    "\n",
    "estimated_means=np.zeros(shape=num_bandits, dtype=float)\n",
    "#--------------------------\n",
    "# the part that truly matters\n",
    "obj=Bandit_arms(num_bandits)\n",
    "estmean=obj.return_array()\n",
    "epsilon = 0.5\n",
    "arr=np.arange(0,num_bandits)\n",
    "def bandit_solving_algo(num_bandits):\n",
    "    global estimated_means\n",
    "    def exploration():\n",
    "        return np.random.choice(arr,size=None)\n",
    "    def exploitation():\n",
    "        return estmean.where(max(estmean))\n",
    "    e1=exploration()\n",
    "    e2=exploitation()\n",
    "    def choose_bandits():\n",
    "        if random.random()>epsilon:\n",
    "            estimated_means[e2]=estmean[e2]\n",
    "        else:\n",
    "            estimated_means[e1]=estmean[e1]\n",
    "    return estimated_means\n",
    "bandit_solving_algo(num_bandits)\n",
    "print(\"Estimated mean rewards\",estimated_means)\n",
    "'''\n",
    "YOUR ALGORITHM MUST NOT USE THE TRUE BANDIT MEAN REWARD ARRAY AT ANY STEP.\n",
    "`num_bandits` VARIABLE PROVIDES YOU THE NUMBER OF BANDITS ARMS AND SIMPLY CALL THE\n",
    "SIMULATOR FUNCTION. ANY ALGORITHM ACCESSING MEAN REWARD ARRAY IS OBVIOUSLY WRONG.\n",
    "'''\n",
    "\n",
    "'''\n",
    "Underlying function checks how well your estimate is. Since, the learning is completed by this point\n",
    "so accessing the true mean for checking is somewhat acceptable.\n",
    "'''\n",
    "def check(bandit_problem, estimate_means):\n",
    "    errors=np.absolute(estimate_means-bandit_problem)\n",
    "    print(\"Error in mean reward prediction for each arm:\",errors)\n",
    "\n",
    "check(bandit_problem, estimated_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13d57e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True mean rewards [0.23 0.19 1.26 2.28 1.28 1.68 2.26 1.99 0.57 0.37 2.28]\n",
      "Estimated mean rewards [1.33 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "Error in mean reward prediction for each arm: [1.1  0.19 1.26 2.28 1.28 1.68 2.26 1.99 0.57 0.37 2.28]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "std=1\n",
    "mean=1\n",
    "'''\n",
    "This class simply generates a bandit problem with number of bandit arms\n",
    "being `num_bandits`, which itself is chosen randomly. The numbers being sampled\n",
    "from the gaussian are the rewards associated with those arms.\n",
    "For simplicity, I have restricted ourselved to nonnegative rewards and decimals upto 2 digits\n",
    "to avoid any floating point calculation errors.\n",
    "'''\n",
    "class Bandit_arms:\n",
    "\n",
    "    def __init__(self, num_bandits):\n",
    "        self.bandits=np.round(np.absolute(np.random.normal(loc=mean, scale=std, size=num_bandits)), decimals=2)\n",
    "\n",
    "    def return_array(self):\n",
    "        return self.bandits\n",
    "\n",
    "\n",
    "'''\n",
    "Minimum: 5 bandit arms and maximum: 20 bandit arms.\n",
    "'''\n",
    "\n",
    "num_bandits=np.random.randint(low=5, high=20,size=1)[0]\n",
    "bandit_problem=Bandit_arms(num_bandits).return_array()\n",
    "print(\"True mean rewards\",bandit_problem)\n",
    "\n",
    "'''\n",
    "This is technically cheating, you should not be aware of the true underlying \n",
    "reward through any means. It doesn't matter as beginners but keep it in mind\n",
    "that this data is unavailable to you (no need for learning if we knew already!).\n",
    "'''\n",
    "\n",
    "'''\n",
    "Now for each arm, when we pull it, we get modulus of number sampled\n",
    "from a gaussian with mean defined in `bandit_problem` array and standard\n",
    "deviation=std.\n",
    "Keep in mind that first bandit arm would have index 0.\n",
    "'''\n",
    "\n",
    "def bandit_simulator(arm_index):\n",
    "    reward=np.round(np.absolute(np.random.normal(loc=bandit_problem[arm_index], scale=std, size=1)), decimals=2)[0]\n",
    "    return reward\n",
    "\n",
    "\n",
    "'''\n",
    "So, now we have an environment that generates a bandit problem\n",
    "with a random number of arms and random mean rewards. We have a function to \n",
    "sample reward on \"pulling\" each of these arms. Now, try out algorithms that \n",
    "can come close to true mean rewards.\n",
    "Any rule based method won't work, since means change everytime you run the python file.\n",
    "So, your algorithm must truly be able to learn as good as it can in a single run of this file.\n",
    "As you must have understood by now, learning is an iterative procedure. Typically, to represent limited\n",
    "computational and time resources, upper limits on allowed learning iterations are imposed. So, I am setting \n",
    "a variable that defines number of allowed iterations. Of course, while building, you can play around with it.\n",
    "'''\n",
    "\n",
    "num_allowed_iterations=2000\n",
    "\n",
    "'''\n",
    "Except for the values of mean, std, num_iterations, I don't think you should\n",
    "have the need to change any of the code written to this point.\n",
    "'''\n",
    "estimated_means=np.zeros(shape=num_bandits, dtype=float)\n",
    "obj=Bandit_arms(num_bandits)\n",
    "value=obj.return_array()\n",
    "#--------------------------\n",
    "# the part that truly matters\n",
    "def bandit_solving_algo(num_bandits):\n",
    "    qt_a=0\n",
    "    nt_a=np.zeros(num_bandits)# number of times a badit has been selected\n",
    "    c=1 # a number that controls degree of exploration\n",
    "    global estimated_means\n",
    "    hist_t=[]\n",
    "    for t in range (0,num_allowed_iterations):\n",
    "        UCB_values=np.zeros(num_bandits)\n",
    "        action_selected =0\n",
    "        for a in range (0,num_bandits):\n",
    "            if (nt_a[a]>0):\n",
    "                ln_t=math.log(t)\n",
    "                hist_t.append(ln_t)\n",
    "                qt_a=sum_rewards[a]/nt_a[a]\n",
    "                ucb_value=qt_a+c*(ln_t/nt_a[a])\n",
    "                UCB_values[a]=ucb_value\n",
    "            elif (nt_a[a]==0):\n",
    "                UCB_values[a]=1e500\n",
    "    action_selected=np.argmax(UCB_values)\n",
    "    nt_a[action_selected]+=1\n",
    "    reward = value[action_selected+1]\n",
    "    estimated_means[action_selected]+=reward\n",
    "    return estimated_means\n",
    "bandit_solving_algo(num_bandits)\n",
    "print(\"Estimated mean rewards\",estimated_means)\n",
    "'''\n",
    "YOUR ALGORITHM MUST NOT USE THE TRUE BANDIT MEAN REWARD ARRAY AT ANY STEP.\n",
    "`num_bandits` VARIABLE PROVIDES YOU THE NUMBER OF BANDITS ARMS AND SIMPLY CALL THE\n",
    "SIMULATOR FUNCTION. ANY ALGORITHM ACCESSING MEAN REWARD ARRAY IS OBVIOUSLY WRONG.\n",
    "'''\n",
    "\n",
    "'''\n",
    "Underlying function checks how well your estimate is. Since, the learning is completed by this point\n",
    "so accessing the true mean for checking is somewhat acceptable.\n",
    "'''\n",
    "def check(bandit_problem, estimate_means):\n",
    "    errors=np.absolute(estimate_means-bandit_problem)\n",
    "    print(\"Error in mean reward prediction for each arm:\",errors)\n",
    "\n",
    "check(bandit_problem, estimated_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2940d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
